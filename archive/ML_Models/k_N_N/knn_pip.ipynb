{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T09:23:00.127621Z",
     "start_time": "2025-06-08T09:23:00.119298Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Temporary Debug Imputer",
   "id": "7a90c33afd76737e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:23:07.527293Z",
     "start_time": "2025-06-08T09:23:07.520977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.impute import KNNImputer as SKKNNImputer\n",
    "class DebugKNNImputer(SKKNNImputer):\n",
    "    \"\"\"\n",
    "    A KNNImputer subclass to log missing values before/after transformation.\n",
    "    Replace KNNImputer with DebugKNNImputer in the pipeline to verify behavior.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        print(f\"[DEBUG] Before fit: missing in training set: {np.isnan(X).sum()} values\")\n",
    "        super().fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xt = super().transform(X)\n",
    "        print(f\"[DEBUG] After transform: missing in data: {np.isnan(Xt).sum()} values\")\n",
    "        return Xt"
   ],
   "id": "5835648b7281494c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Loading\n",
   "id": "ce1d3f58613bd636"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:23:10.166129Z",
     "start_time": "2025-06-08T09:23:10.162328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data():\n",
    "    file_path = '../Data_Processing/nan_df.csv' # Adjust the path as needed\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns = ['Outcome'])\n",
    "    y = df['Outcome']\n",
    "    return X, y\n"
   ],
   "id": "aa8db1796674a588",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Models",
   "id": "973ed44888075d78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:23:17.148740Z",
     "start_time": "2025-06-08T09:23:17.138161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_models(X, y):\n",
    "    #ideal imputer was defined from proc_data.ipynb in a cross-validation test loop.\n",
    "    #imputer = KNNImputer(n_neighbors=5)\n",
    "    imputer = SimpleImputer(strategy='median')  # Use SimpleImputer for simplicity in this example\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #model selection\n",
    "    models = {\n",
    "        'LogisticRegression' : LogisticRegression(solver = 'saga', class_weight = 'balanced', max_iter= 1000, random_state= 42),\n",
    "        'SVC' : SVC(probability = True, class_weight = 'balanced', random_state= 42),\n",
    "        'KNN' : KNeighborsClassifier(),\n",
    "        'RandomForest' : RandomForestClassifier(class_weight = 'balanced', bootstrap= True, random_state= 42)\n",
    "    }\n",
    "\n",
    "    # Hyperparameter grids for each model\n",
    "    param_grids = {\n",
    "        'LogisticRegression' : {\n",
    "            #'clf__' prefix refers to the pipeline step named 'clf', so 'C' becomes 'clf__C'.\n",
    "            'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "            'clf__penalty': ['l2', 'l1', None]\n",
    "\n",
    "        },\n",
    "        'SVC' : {\n",
    "            'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "            'clf__kernel': ['linear'],\n",
    "            #'clf__gamma': ['scale', 'auto']\n",
    "        },\n",
    "        'KNN' : {\n",
    "            'clf__n_neighbors': [3, 5, 7, 15, 20],\n",
    "            'clf__weights': ['uniform', 'distance']\n",
    "        },\n",
    "        'RandomForest' : {\n",
    "            'clf__n_estimators': [50, 100],\n",
    "            'clf__max_depth': [3, 5, 8],\n",
    "            'clf__min_samples_split': [5, 10, 20],\n",
    "            'clf__min_samples_leaf': [2, 5, 10],\n",
    "            'clf__max_features': ['sqrt']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Scoring metrics\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "    # CV splitters\n",
    "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize results dictionary (container for all results)\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    # Loop through each model\n",
    "    for name, base_clf in models.items():\n",
    "        print(f\"\\n### Evaluating {name}... ###\")\n",
    "\n",
    "        #build the pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', imputer),\n",
    "            ('scaler', scaler),\n",
    "            ('clf', base_clf)\n",
    "        ])\n",
    "        # Inner-loop GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grids[name],\n",
    "            scoring=scoring,\n",
    "            refit='recall',  # Refit on recall for best model selection\n",
    "            cv=inner_cv,\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "            return_train_score=False\n",
    "        )\n",
    "\n",
    "        # Outer-loop cross-validation\n",
    "        cv_results = cross_validate(\n",
    "            estimator = grid_search,\n",
    "            X = X,\n",
    "            y = y,\n",
    "            cv=outer_cv,\n",
    "            scoring=scoring,\n",
    "            return_train_score=True,\n",
    "            return_estimator=True,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        # for fold_idx, gs in enumerate(cv_results['estimator']):\n",
    "        #     print(f\"\\n— Fold {fold_idx+1} inner‐CV results —\")\n",
    "        #     print(\" Best params:\", gs.best_params_)\n",
    "        #     # if you enabled multi‐metric scoring:\n",
    "        #     print(\" F1  at best params:\", gs.best_score_)\n",
    "        #     print(\" Prec at best params:\", gs.cv_results_['mean_test_precision'][gs.best_index_])\n",
    "        for fold_idx, gs in enumerate(cv_results['estimator']):\n",
    "            print(f\"\\nFold {fold_idx+1} best inner‐CV params: {gs.best_params_}\")\n",
    "            for metric in scoring.keys():\n",
    "                key = f\"mean_test_{metric}\"\n",
    "             # Some metrics (like roc_auc) may need a different cv_results_ key, but in general:\n",
    "                print(f\"  {metric:8s} = {gs.cv_results_[key][gs.best_index_]:.3f}\")\n",
    "\n",
    "        # Store the raw cross-validate results\n",
    "        all_results[name] = cv_results\n",
    "\n",
    "\n",
    "\n",
    "        # Prepare a summary of results\n",
    "        print(f'\\n Summary for {name}:')\n",
    "        for metric in scoring:\n",
    "            train_scores = cv_results[f'train_{metric}']\n",
    "            test_scores = cv_results[f'test_{metric}']\n",
    "            print(\n",
    "                f' {metric:10s} train: {np.mean(train_scores):.3f} ± {np.std(train_scores):.3f} '\n",
    "                f'test: {np.mean(test_scores):.3f} ± {np.std(test_scores):.3f}'\n",
    "            )\n",
    "    return all_results"
   ],
   "id": "e57b31108989e171",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results",
   "id": "676bf77368a86f9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:18.305006Z",
     "start_time": "2025-06-08T09:24:17.602966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "\n",
    "    #Load data here\n",
    "    X, y = load_data()\n",
    "\n",
    "    #Run nested CV evaluation\n",
    "    results = evaluate_models(X, y)\n",
    "    print(results.keys())\n",
    "    from pprint import pprint\n",
    "    #pprint(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "6f9326adee7911cb",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data_Processing/nan_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m#pprint(results)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 13\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mmain\u001B[39m():\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m#Load data here\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[43mload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m#Run nested CV evaluation\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     results \u001B[38;5;241m=\u001B[39m evaluate_models(X, y)\n",
      "Cell \u001B[1;32mIn[6], line 3\u001B[0m, in \u001B[0;36mload_data\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mload_data\u001B[39m():\n\u001B[0;32m      2\u001B[0m     file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../Data_Processing/nan_df.csv\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;66;03m# Adjust the path as needed\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     X \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop(columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOutcome\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      5\u001B[0m     y \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOutcome\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../Data_Processing/nan_df.csv'"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
